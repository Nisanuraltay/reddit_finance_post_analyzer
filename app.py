import streamlit as st
import pandas as pd
import joblib
import numpy as np

# 1. Modelleri ve Ã–zellikleri YÃ¼kle
try:
    model = joblib.load('reddit_model.pkl')
    features = joblib.load('model_features.pkl')
except Exception as e:
    st.error(f"Model dosyalarÄ± yÃ¼klenemedi: {e}")

st.set_page_config(page_title="Reddit Hype Engine", layout="wide", page_icon="ğŸ“ˆ")

# --- ARAYÃœZ BAÅLIÄI ---
st.title("ğŸ“ˆ Reddit Finance Post Analyzer")
st.markdown("### *Engagement & Hype Risk Engine*")

# --- SIDEBAR: GÄ°RÄ°Å PANELÄ° ---
with st.sidebar:
    st.header("ğŸ” Analiz Parametreleri")
    post_title = st.text_input("Post BaÅŸlÄ±ÄŸÄ± (Title)", "ğŸš€ Buy GME - Diamond Hands! ğŸ’")
    
    sub_list = sorted([c.replace('sub_', '') for c in features if c.startswith('sub_')])
    selected_sub = st.selectbox("Hangi Subreddit?", sub_list)
    
    saat = st.slider("PaylaÅŸÄ±m Saati (0-23)", 0, 23, 14)
    st.divider()
    actual_score = st.number_input("Mevcut BeÄŸeni SayÄ±sÄ± (Score)", min_value=0, value=100)

# --- HESAPLAMA VE ANALÄ°Z MOTORU ---
if st.button("DERÄ°N ANALÄ°ZÄ° BAÅLAT"):
    # Girdi Verisini HazÄ±rla
    input_df = pd.DataFrame(0, index=[0], columns=features)
    if f'sub_{selected_sub}' in features: input_df[f'sub_{selected_sub}'] = 1
    if 'saat' in features: input_df['saat'] = saat
    
    # 1. Tahmin
    pred_log = model.predict(input_df)
    predicted_score = np.expm1(pred_log)[0]
    
    # 2. NLP Analizi
    hype_keywords = ['moon', 'rocket', 'yolo', 'squeeze', 'diamond', 'hands', 'ape', 'pump', 'ğŸš€', 'ğŸ’', 'buy']
    found_hype_words = [word for word in hype_keywords if word in post_title.lower()]
    nlp_risk_bonus = len(found_hype_words) * 10 
    
    # 3. Ä°statistiksel Sapma
    base_diff = actual_score - predicted_score
    stat_risk = (base_diff / (66.33 * 3)) * 100
    final_risk = min(100, max(0, stat_risk + nlp_risk_bonus))

    # --- GÃ–RSEL Ã‡IKTILAR ---
    c1, c2, c3 = st.columns(3)
    c1.metric("Organik Beklenti", f"{int(predicted_score)} Score")
    c2.metric("Hype Riski", f"%{final_risk:.1f}")
    c3.metric("NLP Bonusu", f"+%{nlp_risk_bonus}")

    st.divider()
    
    # Karar Analizi
    st.subheader("ğŸ§  Sistemin Karar Analizi")
    if len(found_hype_words) > 0:
        st.warning(f"âš ï¸ **NLP Sinyali:** BaÅŸlÄ±kta manipÃ¼latif kelimeler bulundu: {', '.join(found_hype_words)}")
    
    if final_risk > 70:
        st.error("ğŸš¨ **KRÄ°TÄ°K:** ManipÃ¼lasyon tespiti! Bu post organik gÃ¶rÃ¼nmÃ¼yor.")
    else:
        st.success("âœ… **GÃœVENLÄ°:** Veriler topluluk normlarÄ±yla uyumlu.")

    # 4. XAI GrafiÄŸi
    st.subheader("ğŸ“Š Model Ã–zellik AÄŸÄ±rlÄ±klarÄ± (XAI)")
    imp_df = pd.DataFrame({'Ã–nem': model.feature_importances_}, index=features).sort_values(by='Ã–nem', ascending=False).head(5)
    st.bar_chart(imp_df)

    # 5. Finansal Grafik
    st.divider()
    st.subheader("ğŸ“‰ Reddit vs. Piyasa OynaklÄ±ÄŸÄ±")
    chart_data = pd.DataFrame(np.random.randn(20, 2), columns=['Hype', 'Fiyat']).cumsum()
    st.line_chart(chart_data)
